{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters-21578 News classification\n",
    "\n",
    "#### Author: Qihao LIU\n",
    "Date: 02/01/2021\n",
    "\n",
    "Reuters-21578 is arguably the most commonly used collection for text classification. It contains structured information about newswire articles that can be assigned to several classes, making it a multi-label problem. \n",
    "It has a highly skewed distribution of documents over categories, where a large proportion of documents belong to few topics. The collection originally consisted of 21,578 documents but a subset and split is traditionally used. \n",
    "The most common split is Mod-Apte which only considers categories that have at least one document in the training set and the test set. The Mod-Apte split has 90 categories with a training set of 7769 documents and a test set of 3019 documents.This method of splitting can directly been used by importing the library nltk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "1. Problem Statement\n",
    "2. Data Cleaning - Data Preparation\n",
    "    * 2.1 Introduction\n",
    "    * 2.2 Getting The Data\n",
    "    * 2.3 Cleaning The Data\n",
    "    * 2.4 Organizing The Data\n",
    "3. Classifying Reuters\n",
    "4. Predictive analysis\n",
    "5. Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Statement\n",
    "\n",
    "The Reuters-21578 dataset contains 21 578 financial articles tagged with topics.\n",
    "There are 135 different topics, but this exercise will focus on only 5 of them:\n",
    "-\tMoney/Foreign Exchange (MONEY-FX)\n",
    "-\tShipping (SHIP)\n",
    "-\tInterest Rates (INTEREST)\n",
    "-\tMergers/Acquisitions (ACQ)\n",
    "-\tEarnings and Earnings Forecasts (EARN)\n",
    "\n",
    "So this is a supervised classification, we do not need to use topic modelling techniques for modelling topics form data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning -  Data Preparation\n",
    "\n",
    "### 2.1 Introduction\n",
    "\n",
    "This part goes through a necessary step of any data science project - data cleaning. Data cleaning is a time consuming and unenjoyable task. Feeding dirty data into a model will give us results that are meaningless.\n",
    "\n",
    "Processing:\n",
    "\n",
    "* Getting the data - in this case, we'll be scraping data from the 22 sgm files containing the 21 578 Reuters articles;\n",
    "* Cleaning the data - we will walk through popular text pre-processing techniques;\n",
    "* Organizing the data - we will organize the cleaned data into a way that is easy to input into other algorithms.\n",
    "\n",
    "The output of this part - organized data in two standard text formats:\n",
    "\n",
    "* Corpus - a collection of text;\n",
    "* Document-Term Matrix: TF-IDF transformation(word importance) or Word2Vec(Each domument with fixed nb of words and each word with fiexed nb of features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Getting The Data\n",
    "\n",
    "There are two ways to get the reuter21578 data:\n",
    "\n",
    "* Download the collection and parse the multiple SGML files in order to recreate the original dataset;\n",
    "* Or, much easier way with the NLTK library which has the reuters corpus already available. \n",
    "\n",
    "Libraies:\n",
    "Using BeautifulSoup libray to help us pick out certain sections from sgml files in order to parse all SGML files, removing all unwanted tags and a simple regex to strip the ending signature.\n",
    "\n",
    "The following code shows how to deal with the original dataset sgml (but actually using NLTK library with Mode-Apte could be efficient):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected categories\n",
    "selected_categories = [\"to_money-fx\",\"to_ship\",\"to_interest\",\"to_acq\",\"to_earn\"] \n",
    "# Category files, add prefix 'to_' for emphasizing the categories are from topics categories\n",
    "category_files = { 'to_': ('Topics', 'all-topics-strings.lc.txt')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name    Type  Newslines\n",
      "0      to_acq  Topics          0\n",
      "1     to_alum  Topics          0\n",
      "2  to_austdlr  Topics          0\n",
      "3  to_austral  Topics          0\n",
      "4   to_barley  Topics          0\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "# Create category dataframe\n",
    "\n",
    "# Read all categories\n",
    "category_data = []\n",
    "\n",
    "# Newsline folder and format\n",
    "data_folder = 'reuter/'\n",
    "\n",
    "# Building dataframe for visualising topics details like numbers of documents to this topic\n",
    "for category_prefix in category_files.keys():\n",
    "    with open(data_folder + category_files[category_prefix][1], 'r') as file:\n",
    "        for category in file.readlines():\n",
    "            category_data.append([category_prefix + category.strip().lower(), \n",
    "                                  category_files[category_prefix][0], 0])\n",
    "\n",
    "# Create category dataframe\n",
    "news_categories = DataFrame(data=category_data, columns=['Name', 'Type', 'Newslines'])\n",
    "print(news_categories.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#update the numbres of documents with same topic (count nbs)\n",
    "def update_frequencies(categories):\n",
    "    \"\"\"function to update the numbres of documents with same topic\n",
    "    ---------------------------------------------\n",
    "    :param:categories, a list of categories from loading reuters' documents\n",
    "    :returns: category dataframe with label 'Newslines' the nbs of documents with same topic\n",
    "    \"\"\"\n",
    "    for category in categories:\n",
    "        idx = news_categories[news_categories.Name == category].index[0]\n",
    "        f = news_categories._get_value(idx, 'Newslines')\n",
    "        news_categories._set_value(idx, 'Newslines', f+1)\n",
    "\n",
    "#building vector Y(labels) for each document to represent whether the documents relative to the topic in \n",
    "#list [\"to_money-fx\",\"to_ship\",\"to_interest\",\"to_acq\",\"to_earn\"]\n",
    "def to_category_vector(categories, target_categories):\n",
    "    \"\"\"function to update the numbres of documents with same topic\n",
    "    ---------------------------------------------\n",
    "    :param: categories, a list of categories from loading reuters' documents\n",
    "            target_categories, the topics that we will selecte like: [\"to_money-fx\",\"to_ship\",\"to_interest\",\"to_acq\",\"to_earn\"] \n",
    "    :returns: a vector of 5 dims for representing whether the documents relative to the topic in target_categories\n",
    "    \"\"\"\n",
    "    vector = np.zeros(len(target_categories)).astype(np.float32)\n",
    "    for i in range(len(target_categories)):\n",
    "        if target_categories[i] in categories:\n",
    "            vector[i] = 1.0\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start parsing reuter/reut2-020.sgm...\n",
      "Start parsing reuter/reut2-001.sgm...\n",
      "Start parsing reuter/reut2-003.sgm...\n",
      "Start parsing reuter/reut2-004.sgm...\n",
      "Start parsing reuter/reut2-007.sgm...\n",
      "Start parsing reuter/reut2-018.sgm...\n",
      "Start parsing reuter/reut2-012.sgm...\n",
      "Start parsing reuter/reut2-011.sgm...\n",
      "Start parsing reuter/reut2-006.sgm...\n",
      "Start parsing reuter/reut2-000.sgm...\n",
      "Start parsing reuter/reut2-005.sgm...\n",
      "Start parsing reuter/reut2-013.sgm...\n",
      "Start parsing reuter/reut2-015.sgm...\n",
      "Start parsing reuter/reut2-014.sgm...\n",
      "Start parsing reuter/reut2-016.sgm...\n",
      "Start parsing reuter/reut2-002.sgm...\n",
      "Start parsing reuter/reut2-021.sgm...\n",
      "Start parsing reuter/reut2-008.sgm...\n",
      "Start parsing reuter/reut2-019.sgm...\n",
      "Start parsing reuter/reut2-009.sgm...\n",
      "Start parsing reuter/reut2-010.sgm...\n",
      "Start parsing reuter/reut2-017.sgm...\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import xml.sax.saxutils as saxutils\n",
    "from glob import glob\n",
    "\n",
    "# Parse SGML files\n",
    "document_X = {}\n",
    "document_Y = {}\n",
    "\n",
    "f_list = glob('reuter/*.sgm')\n",
    "\n",
    "# removing Special symbol like < for reading the specific part in the files\n",
    "#'&amp;','&lt;','&gt;'\n",
    "def strip_tags(text):\n",
    "    return re.sub('<[^<]+?>', '', text).strip()\n",
    "def unescape(text):\n",
    "    return saxutils.unescape(text)\n",
    "\n",
    "# Iterate all files\n",
    "for filename in f_list:\n",
    "    print('Start parsing {0}...'.format(filename))\n",
    "    file = open(filename, 'rb')\n",
    "    content = BeautifulSoup(file.read().lower())\n",
    "    file.close()\n",
    "    for newsline in content('reuters'):\n",
    "        document_categories = []           \n",
    "        # News-line Id\n",
    "        document_id = newsline['newid']\n",
    "        # Extracting document body\n",
    "        document_body = strip_tags(str(newsline('text')[0])).replace('reuter\\n&#3;', '')\n",
    "        document_body = unescape(document_body)\n",
    "        # News-line categories\n",
    "        topics = newsline.topics.contents\n",
    "        for topic in topics:\n",
    "            document_categories.append('to_' + strip_tags(str(topic)))                \n",
    "        # Create new document    \n",
    "        update_frequencies(document_categories)\n",
    "        #Filter the documents in list of [\"to_money-fx\",\"to_ship\",\"to_interest\",\"to_acq\",\"to_earn\"] \n",
    "        if sum(to_category_vector(document_categories, selected_categories))>=1.0:\n",
    "            document_Y[document_id] = to_category_vector(document_categories, selected_categories)\n",
    "            document_X[document_id] = document_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0002\n",
      "u.s. and soviets draft euromissile treaty\n",
      "    geneva, june 2 - u.s. and soviet negotiators have completed\n",
      "the text of a draft treaty calling for the elimination of\n",
      "medium-range missiles in europe, a soviet negotiator said.\n",
      "    \"we must say that as a result of the work done at the\n",
      "current round the sides have drafted the first joint draft text\n",
      "of the treaty on medium-range missiles,\" alexei obukhov, deputy\n",
      "leader of the soviet negotiating team, told reporters.\n",
      "    he said there was still much work to be done and several\n",
      "areas of disagreement remained to be resolved.         \n",
      " reuter\n",
      "\u0003\n"
     ]
    }
   ],
   "source": [
    "print(document_body)\n",
    "#document_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7824\n",
      "7824\n"
     ]
    }
   ],
   "source": [
    "print(len(document_Y))\n",
    "#print(document_Y)\n",
    "print(len(document_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Newslines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>to_earn</td>\n",
       "      <td>Topics</td>\n",
       "      <td>3987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to_acq</td>\n",
       "      <td>Topics</td>\n",
       "      <td>2448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>to_money-fx</td>\n",
       "      <td>Topics</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>to_crude</td>\n",
       "      <td>Topics</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>to_grain</td>\n",
       "      <td>Topics</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>to_trade</td>\n",
       "      <td>Topics</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>to_interest</td>\n",
       "      <td>Topics</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>to_wheat</td>\n",
       "      <td>Topics</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>to_ship</td>\n",
       "      <td>Topics</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>to_corn</td>\n",
       "      <td>Topics</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name    Type  Newslines\n",
       "35       to_earn  Topics       3987\n",
       "0         to_acq  Topics       2448\n",
       "73   to_money-fx  Topics        801\n",
       "28      to_crude  Topics        634\n",
       "45      to_grain  Topics        628\n",
       "126     to_trade  Topics        552\n",
       "55   to_interest  Topics        513\n",
       "130     to_wheat  Topics        306\n",
       "108      to_ship  Topics        305\n",
       "19       to_corn  Topics        254"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(document_X[\"5\"])\n",
    "news_categories.sort_values(by='Newslines', ascending=False, inplace=True)\n",
    "news_categories.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows the numbers of documents relative to the topic that we consider in this exercise, where the sample is not evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Newslines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>to_earn</td>\n",
       "      <td>Topics</td>\n",
       "      <td>3987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to_acq</td>\n",
       "      <td>Topics</td>\n",
       "      <td>2448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>to_money-fx</td>\n",
       "      <td>Topics</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>to_interest</td>\n",
       "      <td>Topics</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>to_ship</td>\n",
       "      <td>Topics</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name    Type  Newslines\n",
       "35       to_earn  Topics       3987\n",
       "0         to_acq  Topics       2448\n",
       "73   to_money-fx  Topics        801\n",
       "55   to_interest  Topics        513\n",
       "108      to_ship  Topics        305"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the indexs selected is the 5 topics in selected_topics\n",
    "news_categories.loc[[35,0,73,55,108]]\n",
    "#print(document_X.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cleaning The Data\n",
    "\n",
    "When dealing with numerical data, data cleaning often involves removing null values and duplicate data, dealing with outliers, etc. With text data, there are some common data cleaning techniques, which are also known as text pre-processing techniques.\n",
    "\n",
    "We're going to execute just the common cleaning steps here:\n",
    "- Make text all lower case\n",
    "- Remove punctuation\n",
    "- Remove numerical values\n",
    "- Remove common non-sensical text (/n)\n",
    "- Tokenize text\n",
    "- Remove stop words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer, SnowballStemmer\n",
    "def tokenize1(text):\n",
    "    \"\"\"function to clean text by removing punctuations, and numbers\n",
    "    ---------------------------------------------\n",
    "    :param text: a string\n",
    "    :returns: string with punctuations, numbers removed and length>=3\n",
    "    \"\"\"\n",
    "    min_length = 3\n",
    "    stopwords_set= set(stopwords.words('english'))\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    text = text.replace('\\n',' ').lower().strip()\n",
    "    text = re.sub(\"[^a-zA-Z]+\", \" \", text).split()\n",
    "    text = ' '.join(stemmer.stem(i) for i in text)\n",
    "    stemmed = ' '.join([word for word in text.split() if word not in stopwords_set and len(word)>=min_length])\n",
    "    return(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7824\n",
      "3333699\n"
     ]
    }
   ],
   "source": [
    "# Tokenized document collection\n",
    "newsline_documents = []\n",
    "word_nb = 0\n",
    "# Tokenize\n",
    "for key in document_X.keys():\n",
    "    newsline_documents.append(tokenize1(document_X[key]))\n",
    "    word_nb += len(tokenize1(document_X[key]))\n",
    "number_of_documents = len(document_X)\n",
    "print(number_of_documents)\n",
    "print(word_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poehl say rate rise caus concern frankfurt oct rise west german intern interest rate caus concern bundesbank interest higher capit market rate bundesbank presid karl otto poehl said consid interest rate increas occur intern problem caus concern poehl told invest confer would like stress bundesbank interest higher capit market rate said short poehl spoke bundesbank announc tender secur repurchas pact fix rate pct previous tender last month interest rate seen alloc rate facil rise pct last week pact last fix rate tender late septemb bundesbank reduct key alloc rate pct herald monday repeat inject money market liquid pct move cap interest rate follow meet poehl financ minist gerhard stoltenberg treasuri secretari jame baker monday frankfurt offici said afterward three men reaffirm commit louvr accord currenc stabil weekend critic baker tighten west german monetari polici prompt sharp fall dollar specul louvr cooper end dollar ralli news monday meet nervous trade trade abov mark tuesday poehl said recent rise interest rate due central bank polici market expect currenc develop comment inflationari expect poehl said get root problem pursu polici reveal ground fear inflationari fear unjustifi exagger said poehl rebuf recent critic west germani say bundesbank made substanti contribut intern cooper interest monetari polici bundesbank toler overshoot money suppli target arous critic quarter said today still lower interest rate end quit contrari countri interest rate risen substanti poehl said taken account consid recent rise repurchas pact alloc rate due rise intern money market rate spill german market said poehl express surpris financi market far ignor improv deficit adjust process trade balanc definit underway said note notic absolut figur spectacular improv budget deficit also attract littl attent said reuter\n"
     ]
    }
   ],
   "source": [
    "print(newsline_documents[10])\n",
    "#print(document_X[\"10\"])\n",
    "#document_X[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Organizing The Data\n",
    "#### 2.4.1 TF-IDF transformation in sklearn\n",
    "\n",
    "At this point, we want to weight each of the features according to their \"importance\" for the document. We are going to use tf-idf where the terms weight is higher the more common in the document, and the more uncommon in the collection they are.\n",
    "\n",
    "Organized data in two standard text formats:\n",
    "* Corpus - a collection of text: list variable --- body_list\n",
    "* Document-Term Matrix: sparse matrix --- matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn TFIDF processing time: 0.26124 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "body_list = newsline_documents\n",
    "start = time.clock()\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(newsline_documents)\n",
    "print (\"sklearn TFIDF processing time: {0:.5f} s\".format(time.clock() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7824, 17972)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#td-idf matrix:\n",
    "matrix_tfidf = vectorizer.transform(newsline_documents)\n",
    "matrix_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label:\n",
    "num_categories = len(selected_categories)\n",
    "topic_class = np.zeros(shape=(number_of_documents, num_categories))\n",
    "for idx, key in enumerate(document_Y.keys()):\n",
    "    topic_class[idx, :] = document_Y[key]\n",
    "topic_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Word2Vec transformation in gensim\n",
    "\n",
    "At this point, we want to train the more efficient dense matrix with Word2Vec method: each domument with fixed nb of words and each word with fiexed nb of features.\n",
    "\n",
    "Organized data in two standard text formats:\n",
    "* Corpus: a collection of text --- newsline_documents\n",
    "* Document-Term Matrix: dense matrix --- X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "###second version of tokenize with more words will be removed\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import PorterStemmer, SnowballStemmer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "\n",
    "#For adapting the word2Vec, rewriting the tokenize function as below: \n",
    "#Make text lowercase, remove text in square brackets,remove punctuation, remove \\n and remove words containing numbers.\n",
    "def tokenize2(text):\n",
    "    min_length = 3\n",
    "    cachedStopWords = stopwords.words(\"english\")\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
    "    words = [word for word in words if word not in cachedStopWords]\n",
    "    tokens =(list(map(lambda token: PorterStemmer().stem(token),words)))\n",
    "    p = re.compile('[\\'a-zA-Z]+') #Matches one or more alphabetical characters.\n",
    "    filtered_tokens = list(filter(lambda token: p.match(token) and len(token)>=min_length,tokens))\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7824\n",
      "489300\n"
     ]
    }
   ],
   "source": [
    "# Tokenized document collection\n",
    "newsline_documents = []\n",
    "word_nb = 0\n",
    "# Tokenize\n",
    "for key in document_X.keys():\n",
    "    newsline_documents.append(tokenize2(document_X[key]))\n",
    "    word_nb += len(tokenize2(document_X[key]))\n",
    "number_of_documents = len(document_X)\n",
    "print(number_of_documents)\n",
    "print(word_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# Word2Vec number of features\n",
    "num_features = 200\n",
    "\n",
    "# Create new Gensim Word2Vec model\n",
    "w2v_model = Word2Vec(newsline_documents, size=num_features, min_count=1, window=10, workers=cpu_count())\n",
    "w2v_model.init_sims(replace=True)\n",
    "w2v_model.save(data_folder + 'reuters.word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7824, 100, 200)\n",
      "(7824, 5)\n"
     ]
    }
   ],
   "source": [
    "# Limit each newsline to a fixed number of words\n",
    "document_max_num_words = 100\n",
    "num_categories = len(selected_categories)\n",
    "X = np.zeros(shape=(number_of_documents, document_max_num_words, num_features)).astype(np.float32)\n",
    "Y = np.zeros(shape=(number_of_documents, num_categories)).astype(np.float32)\n",
    "\n",
    "empty_word = np.zeros(num_features).astype(np.float32)\n",
    "for idx, document in enumerate(newsline_documents):\n",
    "    for jdx, word in enumerate(document):\n",
    "        if jdx == document_max_num_words:\n",
    "            break            \n",
    "        else:\n",
    "            if word in w2v_model:\n",
    "                X[idx, jdx, :] = w2v_model[word]\n",
    "            else:\n",
    "                X[idx, jdx, :] = empty_word\n",
    "for idx, key in enumerate(document_Y.keys()):\n",
    "    Y[idx, :] = document_Y[key]\n",
    "    \n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classifying Reuters \n",
    "\n",
    "\n",
    "In order to classify the collection, we have to apply a number of steps which are standard for the majority of classification problems:\n",
    "\n",
    "* Define our training and testing subsets to make sure that we do not evaluate with documents that the system has learnt from. In our case, split train and test dataset with ratio of 0.3.\n",
    "* Represent all the documents in each subset.\n",
    "* Train a classifier on the represented training data.\n",
    "* Predict the labels for each one of the represented testing documents.\n",
    "* Compare the real and predicted document labels to evaluate our solution.\n",
    "\n",
    "Model:\n",
    "* Using model linear SVM (LinearSVC), this model has traditionally produced good quality with text classification problems;\n",
    "* and Gaussian Naive Bayes (GaussianNB or MultinomialNB).\n",
    "\n",
    "The problem we are solving has a multi-label nature, we have to train our model (which is binary by nature) N times, once per category, where the negative cases will be the documents in all the other categories. This allows our model to make a binary decision per category and produce multi-label results. This can be done with the OneVsRestClassifier object in Scikit-learn. This step might change depending on the estimator like kNN which is multi-label by nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Classifying Reuters with TF-IDF transformation\n",
    "\n",
    "* Split train and test dataset with ratio of 0.3;\n",
    "* Using SVM and MultinomialNB methods for traning models;\n",
    "* Using cross validation(cross_val_score in sklearn) for evaluating the models;\n",
    "* Test on test dataset with the params of micro/macro Precision, Recall, F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5476, 17972)\n",
      "(5476, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "#split train and test dataset with ratio of 0.3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(matrix_tfidf, topic_class, test_size=0.3)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "##param list:\n",
    "# estimator:clf\n",
    "# X：(Features)\n",
    "# y：(Labels)\n",
    "# soring：accuracy,mean_squared_error..\n",
    "# cv：nb of flod\n",
    "# n_jobs：nb of cpus（-1 for all）\n",
    "\n",
    "def cross_validation(clf,num_folds = 10):\n",
    "    # logger.info(\"Cross validation\")\n",
    "    print(\"Cross validation\")\n",
    "    scores = cross_val_score(clf,\n",
    "                             X_train, Y_train,\n",
    "                             cv=num_folds,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=0)\n",
    "    print(f\"Real risk by {num_folds}-fold CV : {scores.mean():.2} (+/- {scores.std():.2})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def evaluate(test_labels, predictions):\n",
    "    precision = precision_score(test_labels, predictions, average='micro')\n",
    "    recall = recall_score(test_labels, predictions, average='micro')\n",
    "    f1 = f1_score(test_labels, predictions, average='micro')\n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "    precision = precision_score(test_labels, predictions,average='macro')\n",
    "    recall = recall_score(test_labels, predictions, average='macro')\n",
    "    f1 = f1_score(test_labels, predictions, average='macro')\n",
    "\n",
    "    print(\"Macro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Linear SVM method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def linearsvc_classifier(train_docs, train_labels):\n",
    "    #classifier = LinearSVC([\"penalty='l2'\", \"loss='squared_hinge'\", \"multi_class='ovr'\"])\n",
    "    classifier = OneVsRestClassifier(LinearSVC(random_state=42))\n",
    "    classifier.fit(train_docs, train_labels)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation\n",
      "Real risk by 10-fold CV : 0.94 (+/- 0.0097)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(OneVsRestClassifier(LinearSVC(random_state=42)))\n",
    "#cross_validation(LinearSVC([\"penalty='l2'\", \"loss='squared_hinge'\", \"multi_class='ovr'\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.9678, Recall: 0.9598, F1-measure: 0.9638\n",
      "Macro-average quality numbers\n",
      "Precision: 0.9439, Recall: 0.9199, F1-measure: 0.9310\n"
     ]
    }
   ],
   "source": [
    "#documents = reuters.fileids()\n",
    "model_svm = linearsvc_classifier(X_train, Y_train)\n",
    "predictions_svm = model_svm.predict(X_test)\n",
    "evaluate(Y_test, predictions_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.9940, Recall: 0.9975, F1-measure: 0.9958\n",
      "Macro-average quality numbers\n",
      "Precision: 0.9851, Recall: 0.9931, F1-measure: 0.9891\n"
     ]
    }
   ],
   "source": [
    "model_svm = linearsvc_classifier(X_train, Y_train)\n",
    "predictions_svm = model_svm.predict(X_train)\n",
    "evaluate(Y_train, predictions_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "\n",
    "def naive_classifier(train_docs, train_labels):\n",
    "    classifier = OneVsRestClassifier(MultinomialNB(alpha=0.01))\n",
    "    classifier.fit(train_docs, train_labels)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation\n",
      "Real risk by 10-fold CV : 0.84 (+/- 0.017)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(OneVsRestClassifier(MultinomialNB(alpha=0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.8788, Recall: 0.9254, F1-measure: 0.9015\n",
      "Macro-average quality numbers\n",
      "Precision: 0.8304, Recall: 0.9303, F1-measure: 0.8701\n"
     ]
    }
   ],
   "source": [
    "model_naive = naive_classifier(X_train, Y_train)\n",
    "predictions_navie = model_naive.predict(X_test)\n",
    "evaluate(Y_test, predictions_navie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.9419, Recall: 0.9851, F1-measure: 0.9630\n",
      "Macro-average quality numbers\n",
      "Precision: 0.8888, Recall: 0.9900, F1-measure: 0.9294\n"
     ]
    }
   ],
   "source": [
    "model_naive = naive_classifier(X_train, Y_train)\n",
    "predictions_navie = model_naive.predict(X_train)\n",
    "evaluate(Y_train, predictions_navie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Classifying Reuters with Word2Vec transformation\n",
    "* New idea: Average 100 word vectors of each document: X (shape:7824,100,200) to X (shape:7824,200)\n",
    "* Split train and test dataset with ratio of 0.3;\n",
    "* Using SVM and GaussianNB methods for traning models;\n",
    "* Using cross validation(cross_val_score in sklearn) for evaluating the models;\n",
    "* Test on test dataset with the params of micro/macro Precision, Recall, F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5476, 200)\n",
      "(5476, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#average word vector in each document: X (shape:7824*100*200) to X (shape:7824*200)\n",
    "matrix_word2vec = X.sum(axis = 1)/100\n",
    "topic_class = Y\n",
    "#split train and test dataset with ratio of 0.3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(matrix_word2vec, topic_class, test_size=0.3)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Linear SVM method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation\n",
      "Real risk by 10-fold CV : 0.83 (+/- 0.021)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(OneVsRestClassifier(LinearSVC(random_state=42)),num_folds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.9511, Recall: 0.8696, F1-measure: 0.9085\n",
      "Macro-average quality numbers\n",
      "Precision: 0.9068, Recall: 0.7217, F1-measure: 0.7949\n"
     ]
    }
   ],
   "source": [
    "#documents = reuters.fileids()\n",
    "model = linearsvc_classifier(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "evaluate(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.9421, Recall: 0.8649, F1-measure: 0.9018\n",
      "Macro-average quality numbers\n",
      "Precision: 0.9005, Recall: 0.7168, F1-measure: 0.7889\n"
     ]
    }
   ],
   "source": [
    "#documents = reuters.fileids()\n",
    "model = linearsvc_classifier(X_train, Y_train)\n",
    "predictions = model.predict(X_train)\n",
    "evaluate(Y_train, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def naive_classifier(train_docs, train_labels):\n",
    "    classifier = OneVsRestClassifier(GaussianNB())\n",
    "    classifier.fit(train_docs, train_labels)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation\n",
      "Real risk by 10-fold CV : 0.63 (+/- 0.024)\n"
     ]
    }
   ],
   "source": [
    "cross_validation(OneVsRestClassifier(GaussianNB()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5476, 5)\n",
      "(5476, 200)\n",
      "Micro-average quality numbers\n",
      "Precision: 0.6715, Recall: 0.8559, F1-measure: 0.7526\n",
      "Macro-average quality numbers\n",
      "Precision: 0.5587, Recall: 0.8089, F1-measure: 0.6378\n"
     ]
    }
   ],
   "source": [
    "# print(Y_train.shape)\n",
    "# print(X_train.shape)\n",
    "model = naive_classifier(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "evaluate(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average quality numbers\n",
      "Precision: 0.6798, Recall: 0.8516, F1-measure: 0.7560\n",
      "Macro-average quality numbers\n",
      "Precision: 0.5720, Recall: 0.8130, F1-measure: 0.6493\n"
     ]
    }
   ],
   "source": [
    "model = naive_classifier(X_train, Y_train)\n",
    "predictions = model.predict(X_train)\n",
    "evaluate(Y_train, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RandomForestRegressor model\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# RF = RandomForestRegressor(n_estimators=10, criterion=\"mae\", max_depth=3)\n",
    "# RF.fit(X_train, Y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "# evaluate(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predictive analysis\n",
    "\n",
    "Our samples are nobalanced distributed:\n",
    "*\t    Name\t     Type\tNewslines\n",
    "* 35\tto_earn\t     Topics\t 3987\n",
    "* 0\t   to_acq\t     Topics\t2448\n",
    "* 73\tto_money-fx\t   Topics 801\n",
    "* 55\tto_interest \tTopics 513\n",
    "* 108\tto_ship\t      Topics 305\n",
    "\n",
    "So Micro-average will better performed because it considers this nobalanced problem in its formula:\n",
    "\n",
    "TF-IDF transformation(same case for Word2Vec):\n",
    "\n",
    "Linear SVM (LinearSVC):\n",
    "* Micro-average quality numbers\n",
    "* Precision: 0.9678, Recall: 0.9598, F1-measure: 0.9638\n",
    "* Macro-average quality numbers\n",
    "* Precision: 0.9439, Recall: 0.9199, F1-measure: 0.9310\n",
    "\n",
    "Gaussian Naive Bayes (GaussianNB):\n",
    "* Micro-average quality numbers\n",
    "* Precision: 0.8788, Recall: 0.9254, F1-measure: 0.9015\n",
    "* Macro-average quality numbers\n",
    "* Precision: 0.8304, Recall: 0.9303, F1-measure: 0.8701\n",
    "\n",
    "Results:\n",
    "* We could see Linear SVM preform much better than Naive Bayes in both two transformation problem;\n",
    "* With new methods of averaging Word2Vec(averaging words vector in one document), Word2Vec could will perform with Linear SVM, but bad performing with Naive Bayes;\n",
    "* With new methods of averaging Word2Vec, the dim of dataset(7824, 200) are much lower than that of TF-IDF (7824, 17972), and when we use SVM method, the performences are also good:\n",
    "    * Micro-average quality numbers\n",
    "    * Precision: 0.9511, Recall: 0.8696, F1-measure: 0.9085\n",
    "    * Macro-average quality numbers\n",
    "    * Precision: 0.9068, Recall: 0.7217, F1-measure: 0.7949\n",
    "* Word2Vec could be used in neural network when we want to deal with all categories, but in our problem with the low dim features espace, the ML method will be sufficient to well classifier the documents:\n",
    "    * CNN + word2vec\n",
    "    * LSTM + word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Topic Modeling\n",
    "\n",
    "In this case, our problem is supervised. Generally, NLP problems are unsupervised which need to do the topic modeling. The ultimate goal of topic modeling is to find various topics that are present in the corpus. Each document in the corpus will be made up of at least one topic, if not multiple topics.\n",
    "\n",
    "Method: Latent Dirichlet Allocation (LDA), which is one of many topic modeling techniques. It was specifically designed for text data.\n",
    "\n",
    "To use a topic modeling technique, we need to provide \n",
    "* a document-term matrix;\n",
    "* and the number of topics we would like the algorithm to pick up.\n",
    "\n",
    "Once the topic modeling technique is applied, our job as a human is to interpret the results and see if the mix of words in each topic make sense. If they don't make sense, we can try changing up the number of topics, the terms in the document-term matrix, model parameters, or even try a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Getting reuters dataset from NLTK library\n",
    "\n",
    "The most common split is Mod-Apte which only considers categories that have at least one document in the training set and the test set. The Mod-Apte split has 90 categories with a training set of 7769 documents and a test set of 3019 documents.This method of splitting can directly been used by library nltk.\n",
    "\n",
    "Useful blog:\n",
    "https://martin-thoma.com/nlp-reuters/\n",
    "https://ana.cachopo.org/datasets-for-single-label-text-categorization\n",
    "https://towardsdatascience.com/analysis-and-visualization-of-unstructured-text-data-2de07d9adc84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thanks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
